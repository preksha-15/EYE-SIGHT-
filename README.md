# EYE-SIGHT-
AI-Based Reading Assistant for Visually Impaired people

**Introduction**
This project, EYE-SIGHT, develops a low-cost, AI-powered reading assistant. It converts text from images (printed and handwritten) into speech using Optical Character Recognition (OCR), language detection, and Text-to-Speech (TTS) technologies, enabling visually impaired users to instantly hear content.

**Features**
1) Text-to-Speech Conversion: Converts text from images into audible speech.
2) Optical Character Recognition (OCR): Extracts text from both printed and handwritten sources using EasyOCR.
3) Automatic Language Detection: Identifies the language of the extracted text using langdetect.
4) User-Friendly Interface: Built with Gradio for accessibility.
5) Real-time Processing: Achieves low latency for quick content delivery.

**Proposed Methodology**
The system uses a sequential approach:
1) Image Input: User uploads or captures an image containing text.
2) Text Extraction: EasyOCR extracts text from the image.
3) Language Detection: langdetect identifies the language of the extracted text.
4) Text-to-Speech Conversion: gTTS converts the text into an audio file.
5) Audio Playback: The generated audio is played back to the user.

**ACKNOWLEDGEMENT**
[Preksha Agarwal,](https://github.com/preksha-15)
[Samiul Haque Azmi (Lead),](https://github.com/Sami0137)
[Vinayak Sharma,](https://github.com/LyNx-ViNaYaK-2005)
[Priya,](https://github.com/Priya430136)
Shorya Dixit
